{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect of Sparsification on Graph Topology\n",
    "\n",
    "This notebook analyzes how different sparsification methods (Random, Jaccard, Adamic-Adar, Effective Resistance, Metric Backbone) affect the topological properties of the graph, such as degree distribution, density, and connectivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str(Path.cwd().parent.parent))\n",
    "\n",
    "from src import (\n",
    "    DatasetLoader,\n",
    "    GraphSparsifier,\n",
    "    set_global_seed,\n",
    "    compute_graph_stats,\n",
    "    print_text_table,\n",
    "    calculate_jaccard_scores,\n",
    "    calculate_adamic_adar_scores\n",
    ")\n",
    "from src.sparsification.metrics import calculate_approx_effective_resistance_scores\n",
    "from src.sparsification.metric_backbone import metric_backbone_sparsify\n",
    "from torch_geometric.utils import to_scipy_sparse_matrix, sort_edge_index\n",
    "\n",
    "set_global_seed(42)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "else:\n",
    "    DEVICE = \"cpu\"\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "We begin by importing the necessary libraries and setting up our computational environment. We configure the device (GPU if available, otherwise CPU) and set a random seed for reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Loading\n",
    "\n",
    "We load three benchmark graph datasets (Cora, Flickr, PubMed) that are commonly used in graph neural network research. These datasets vary in size and structure, allowing us to evaluate how sparsification methods generalize across different graph topologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DatasetLoader(root=\"../data\")\n",
    "\n",
    "dataset_names = [\"cora\", \"flickr\", \"pubmed\"]\n",
    "datasets = {}\n",
    "\n",
    "for name in dataset_names:\n",
    "    data, _, _ = loader.get_dataset(name, DEVICE)\n",
    "    datasets[name] = data\n",
    "    print(f\"Loaded {name.capitalize()}: {data.num_nodes:,} nodes, {data.edge_index.shape[1]:,} edges\")\n",
    "\n",
    "print(f\"\\nTotal datasets loaded: {len(datasets)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Characteristics\n",
    "\n",
    "The datasets have been successfully loaded. Each dataset represents a different scale and domain:\n",
    "- **Cora**: A citation network with moderate size\n",
    "- **Flickr**: A social network with higher connectivity\n",
    "- **PubMed**: A larger citation network with different structural properties\n",
    "\n",
    "These variations allow us to assess how sparsification methods perform across different graph characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparsification Analysis Function\n",
    "\n",
    "We define a function to analyze how graph topology changes under different sparsification strategies. The function:\n",
    "1. Computes baseline topological statistics (degree distribution, density, connectivity)\n",
    "2. Calculates edge importance scores using the specified method:\n",
    "   - **Random**: Uniformly random scores (baseline)\n",
    "   - **Jaccard**: Similarity based on neighborhood overlap\n",
    "   - **Adamic-Adar**: Weighted by inverse log-degree of common neighbors\n",
    "   - **Effective Resistance**: Electrical distance measuring criticality of edges (bridges have high resistance)\n",
    "   - **Metric Backbone**: Removes redundant edges using the Relaxed Triangle Inequality\n",
    "3. Progressively removes edges based on these scores at various retention rates\n",
    "4. Tracks how topological properties evolve as the graph becomes sparser\n",
    "\n",
    "Note: Metric Backbone uses a different approach (alpha parameter) rather than retention rates, so it's handled separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sparsification_topology(data, method, retention_rates):\n",
    "    \"\"\"\n",
    "    Sparsifies the graph at different rates and computes topological stats.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    results[\"Original\"] = compute_graph_stats(data)\n",
    "    \n",
    "    if method == 'random':\n",
    "        scores = torch.rand(data.edge_index.shape[1], device=DEVICE)\n",
    "        edge_index = data.edge_index\n",
    "        \n",
    "    elif method == 'jaccard':\n",
    "        edge_index_cpu = data.edge_index.cpu()\n",
    "        adj = to_scipy_sparse_matrix(edge_index_cpu, num_nodes=data.num_nodes).tocsr()\n",
    "        \n",
    "        scores_np = calculate_jaccard_scores(adj)\n",
    "        \n",
    "        adj.data = scores_np\n",
    "        adj_coo = adj.tocoo()\n",
    "        \n",
    "        row = torch.from_numpy(adj_coo.row).to(torch.long).to(DEVICE)\n",
    "        col = torch.from_numpy(adj_coo.col).to(torch.long).to(DEVICE)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "        scores = torch.from_numpy(adj_coo.data).to(torch.float).to(DEVICE)\n",
    "        \n",
    "    elif method == 'adamic-adar':\n",
    "        edge_index_cpu = data.edge_index.cpu()\n",
    "        adj = to_scipy_sparse_matrix(edge_index_cpu, num_nodes=data.num_nodes).tocsr()\n",
    "        \n",
    "        scores_np = calculate_adamic_adar_scores(adj)\n",
    "        \n",
    "        adj.data = scores_np\n",
    "        adj_coo = adj.tocoo()\n",
    "        \n",
    "        row = torch.from_numpy(adj_coo.row).to(torch.long).to(DEVICE)\n",
    "        col = torch.from_numpy(adj_coo.col).to(torch.long).to(DEVICE)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "        scores = torch.from_numpy(adj_coo.data).to(torch.float).to(DEVICE)\n",
    "        \n",
    "    elif method == 'approx-effective-resistance':\n",
    "        edge_index_cpu = data.edge_index.cpu()\n",
    "        adj = to_scipy_sparse_matrix(edge_index_cpu, num_nodes=data.num_nodes).tocsr()\n",
    "        \n",
    "        # Use approximate effective resistance (JL-projection based, O(m log n))\n",
    "        scores_np = calculate_approx_effective_resistance_scores(adj)\n",
    "        \n",
    "        adj.data = scores_np\n",
    "        adj_coo = adj.tocoo()\n",
    "        \n",
    "        row = torch.from_numpy(adj_coo.row).to(torch.long).to(DEVICE)\n",
    "        col = torch.from_numpy(adj_coo.col).to(torch.long).to(DEVICE)\n",
    "        edge_index = torch.stack([row, col], dim=0)\n",
    "        scores = torch.from_numpy(adj_coo.data).to(torch.float).to(DEVICE)\n",
    "        \n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "        \n",
    "    for rate in retention_rates:\n",
    "        k = int(rate * edge_index.shape[1])\n",
    "        \n",
    "        if k > 0:\n",
    "            _, indices = torch.topk(scores, k)\n",
    "            subset_edge_index = edge_index[:, indices]\n",
    "        else:\n",
    "            subset_edge_index = torch.empty((2, 0), dtype=torch.long, device=DEVICE)\n",
    "            \n",
    "        class SparseGraph:\n",
    "            def __init__(self, edge_index, num_nodes):\n",
    "                self.edge_index = edge_index\n",
    "                self.num_nodes = num_nodes\n",
    "        \n",
    "        sparse_data = SparseGraph(subset_edge_index, data.num_nodes)\n",
    "        results[f\"Ret {rate:.1f}\"] = compute_graph_stats(sparse_data)\n",
    "    return results\n",
    "\n",
    "def analyze_metric_backbone_topology(data, alpha_values):\n",
    "    \"\"\"\n",
    "    Sparsifies the graph using metric backbone with different alpha values.\n",
    "    Uses Jaccard distance (1 - Jaccard similarity) as the edge metric.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    results[\"Original\"] = compute_graph_stats(data)\n",
    "    \n",
    "    edge_index_cpu = data.edge_index.cpu()\n",
    "    adj = to_scipy_sparse_matrix(edge_index_cpu, num_nodes=data.num_nodes).tocsr()\n",
    "    \n",
    "    jaccard_sim = calculate_jaccard_scores(adj)\n",
    "    jaccard_dist = 1.0 - jaccard_sim\n",
    "    \n",
    "    for alpha in alpha_values:\n",
    "        sparse_data, stats = metric_backbone_sparsify(data, jaccard_dist, alpha=alpha, verbose=False)\n",
    "        retention_rate = stats['retention_ratio']\n",
    "        results[f\"α={alpha:.1f} ({retention_rate:.1%})\"] = compute_graph_stats(sparse_data)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Sparsification Experiments\n",
    "\n",
    "We now systematically apply five sparsification methods across all datasets:\n",
    "- **Random**: Removes edges uniformly at random (baseline)\n",
    "- **Jaccard**: Preserves edges between nodes with high neighborhood overlap\n",
    "- **Adamic-Adar**: Prioritizes edges connecting nodes through low-degree intermediaries\n",
    "- **Effective Resistance**: Retains edges with high electrical resistance (bridges, bottlenecks)\n",
    "- **Metric Backbone**: Uses the Relaxed Triangle Inequality to remove redundant edges where efficient detours exist\n",
    "\n",
    "For the first four methods, we test retention rates from 90% down to 10% in 10% increments. For Metric Backbone, we vary the alpha parameter (stretch factor) which controls the redundancy threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"random\", \"jaccard\", \"adamic-adar\", \"approx-effective-resistance\"] \n",
    "retention_rates = [1-0.1*i for i in range(1,10)]\n",
    "alpha_values = [1.0, 1.5, 2.0, 3.0, 5.0, 10.0]\n",
    "\n",
    "all_results = {} \n",
    "\n",
    "for name, data in datasets.items():\n",
    "    all_results[name] = {}\n",
    "    print(f\"\\n{'='*30}\\n DATASET: {name.capitalize()}\\n{'='*30}\")\n",
    "    \n",
    "    for method in methods:\n",
    "        print(f\"\\nRunning {method.capitalize()} sparsification...\")\n",
    "        try:\n",
    "            stats = analyze_sparsification_topology(data, method, retention_rates)\n",
    "            all_results[name][method] = stats\n",
    "            \n",
    "            print_text_table(\n",
    "                stats, \n",
    "                title=f\"{name.capitalize()} - {method.capitalize()} Topology\", \n",
    "                col_width=12\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to run {method} on {name}: {e}\")\n",
    "    \n",
    "    print(f\"\\nRunning Metric Backbone sparsification...\")\n",
    "    try:\n",
    "        stats = analyze_metric_backbone_topology(data, alpha_values)\n",
    "        all_results[name]['metric-backbone'] = stats\n",
    "        \n",
    "        print_text_table(\n",
    "            stats,\n",
    "            title=f\"{name.capitalize()} - Metric Backbone Topology\",\n",
    "            col_width=15\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to run metric-backbone on {name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topological Statistics Summary\n",
    "\n",
    "The tables above show how key graph properties evolve under sparsification:\n",
    "\n",
    "**Key Observations:**\n",
    "- **Average Degree**: Decreases approximately linearly with retention rate for threshold-based methods (Random, Jaccard, Adamic-Adar, Effective Resistance)\n",
    "- **Density**: Becomes sparser as edges are removed, particularly noticeable in denser graphs\n",
    "- **Connected Components**: May fragment as critical bridging edges are removed\n",
    "- **Method Differences**: Structural methods (Jaccard, Adamic-Adar, Effective Resistance) tend to preserve connectivity better than random removal at equivalent retention rates\n",
    "- **Effective Resistance**: Identifies critical edges (bridges) with high resistance; preserving these maintains graph connectivity\n",
    "- **Metric Backbone**: Operates differently by identifying redundant edges based on the triangle inequality. Lower alpha values are more aggressive, removing edges where efficient detours exist. The retention ratio varies based on graph structure.\n",
    "\n",
    "These results demonstrate that not all edges are equal for maintaining graph structure—intelligently selecting which edges to retain can preserve topological integrity better than random pruning. Metric Backbone provides a principled geometric approach by identifying edges that are \"shortcuts\" in the graph's metric space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Degree Evolution\n",
    "\n",
    "We visualize how the average node degree changes as we progressively remove edges. This plot helps us understand:\n",
    "- The rate of structural degradation under each method\n",
    "- Whether different methods preserve degree distribution differently\n",
    "- How dataset characteristics influence sparsification behavior\n",
    "\n",
    "Note: Metric Backbone is not included in this plot as it uses a different parameterization (alpha) rather than explicit retention rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, name in enumerate(dataset_names):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(f\"{name.capitalize()} - Avg Degree Decay\", fontsize=14)\n",
    "    \n",
    "    for method in methods:\n",
    "        if method not in all_results[name]:\n",
    "            continue\n",
    "            \n",
    "        stats_dict = all_results[name][method]\n",
    "        \n",
    "        rates = []\n",
    "        values = []\n",
    "        \n",
    "        for key, metrics in stats_dict.items():\n",
    "            if key == \"Original\":\n",
    "                r = 1.0\n",
    "            else:\n",
    "                r = float(key.split(\" \")[1])\n",
    "            \n",
    "            rates.append(r)\n",
    "            values.append(metrics[\"avg_degree\"])\n",
    "            \n",
    "        sorted_pairs = sorted(zip(rates, values), reverse=True)\n",
    "        xs, ys = zip(*sorted_pairs)\n",
    "        \n",
    "        plt.plot(xs, ys, marker='o', linewidth=2, label=method.capitalize())\n",
    "        \n",
    "    plt.xlabel(\"Retention Rate\")\n",
    "    plt.ylabel(\"Average Degree\")\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree Decay Analysis\n",
    "\n",
    "The plots reveal that average degree decreases approximately linearly with retention rate across all methods and datasets. This is expected since we're removing a fixed proportion of edges. The similarity of curves across methods suggests that at the aggregate level, all three approaches remove edges at comparable rates—the key differences lie in *which* edges are removed, not *how many*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Overlap Analysis\n",
    "\n",
    "To understand whether different sparsification methods select similar or different edges, we compute the Jaccard similarity between the edge sets retained by each method pair. High overlap indicates the methods agree on which edges are important, while low overlap suggests they capture different aspects of graph structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_set(edge_index):\n",
    "    \"\"\"Converts edge_index to a set of undirected edges (u, v) where u < v.\"\"\"\n",
    "    src, dst = edge_index\n",
    "    mask = src < dst\n",
    "    edges = torch.stack([src[mask], dst[mask]], dim=1)\n",
    "    return set(map(tuple, edges.cpu().numpy().tolist()))\n",
    "\n",
    "def compute_method_scores(data, method):\n",
    "    \"\"\"Compute scores ONCE for a method - this is the expensive operation.\"\"\"\n",
    "    if method == 'random':\n",
    "        return torch.rand(data.edge_index.shape[1], device=DEVICE), data.edge_index\n",
    "    \n",
    "    edge_index_cpu = data.edge_index.cpu()\n",
    "    adj = to_scipy_sparse_matrix(edge_index_cpu, num_nodes=data.num_nodes).tocsr()\n",
    "    \n",
    "    if method == 'jaccard':\n",
    "        scores_np = calculate_jaccard_scores(adj)\n",
    "    elif method == 'adamic-adar':\n",
    "        scores_np = calculate_adamic_adar_scores(adj)\n",
    "    elif method in ('effective-resistance', 'approx-effective-resistance'):\n",
    "        scores_np = calculate_approx_effective_resistance_scores(adj)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method: {method}\")\n",
    "    \n",
    "    adj.data = scores_np\n",
    "    adj_coo = adj.tocoo()\n",
    "    row = torch.from_numpy(adj_coo.row).to(torch.long).to(DEVICE)\n",
    "    col = torch.from_numpy(adj_coo.col).to(torch.long).to(DEVICE)\n",
    "    edge_index = torch.stack([row, col], dim=0)\n",
    "    scores = torch.from_numpy(adj_coo.data).to(torch.float).to(DEVICE)\n",
    "    return scores, edge_index\n",
    "\n",
    "def get_sparsified_edges_from_scores(scores, edge_index, rate):\n",
    "    \"\"\"Get sparsified edges using precomputed scores (fast).\"\"\"\n",
    "    k = int(rate * edge_index.shape[1])\n",
    "    if k > 0:\n",
    "        _, indices = torch.topk(scores, k)\n",
    "        subset_edge_index = edge_index[:, indices]\n",
    "    else:\n",
    "        subset_edge_index = torch.empty((2, 0), dtype=torch.long, device=DEVICE)\n",
    "    return get_edge_set(subset_edge_index)\n",
    "\n",
    "# Generate pairs dynamically from methods list\n",
    "pairs = [(methods[i], methods[j]) for i in range(len(methods)) for j in range(i+1, len(methods))]\n",
    "\n",
    "plot_data = {}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    print(f\"\\n{'='*30}\\n OVERLAP ANALYSIS: {name.capitalize()}\\n{'='*30}\")\n",
    "    \n",
    "    # Precompute scores ONCE per method (expensive part)\n",
    "    print(\"Precomputing scores...\")\n",
    "    method_cache = {}\n",
    "    for method in methods:\n",
    "        print(f\"  {method}...\", end=\" \", flush=True)\n",
    "        method_cache[method] = compute_method_scores(data, method)\n",
    "        print(\"done\")\n",
    "    \n",
    "    dataset_overlaps = {}\n",
    "    plot_data[name] = {f\"{p[0]} vs {p[1]}\": {'rates': [], 'overlaps': []} for p in pairs}\n",
    "    \n",
    "    # Now iterate over retention rates using cached scores (fast)\n",
    "    for rate in retention_rates:\n",
    "        edge_sets = {}\n",
    "        for method in methods:\n",
    "            scores, edge_index = method_cache[method]\n",
    "            edge_sets[method] = get_sparsified_edges_from_scores(scores, edge_index, rate)\n",
    "            \n",
    "        rate_stats = {}\n",
    "        for m1, m2 in pairs:\n",
    "            set1 = edge_sets[m1]\n",
    "            set2 = edge_sets[m2]\n",
    "            \n",
    "            if len(set1) == 0 and len(set2) == 0:\n",
    "                jaccard_sim = 1.0\n",
    "            else:\n",
    "                intersection = len(set1.intersection(set2))\n",
    "                union = len(set1.union(set2))\n",
    "                jaccard_sim = intersection / union\n",
    "            \n",
    "            pair_key = f\"{m1} vs {m2}\"\n",
    "            rate_stats[pair_key] = jaccard_sim\n",
    "            plot_data[name][pair_key]['rates'].append(rate)\n",
    "            plot_data[name][pair_key]['overlaps'].append(jaccard_sim)\n",
    "            \n",
    "        dataset_overlaps[f\"Ret {rate:.1f}\"] = rate_stats\n",
    "        \n",
    "    print_text_table(\n",
    "        dataset_overlaps,\n",
    "        title=f\"{name.capitalize()} - Edge Overlap (Jaccard Similarity)\",\n",
    "        col_width=20,\n",
    "        float_fmt=\"{:.2%}\"\n",
    "    )\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, name in enumerate(dataset_names):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(f\"{name.capitalize()} - Method Overlap\", fontsize=14)\n",
    "    \n",
    "    for pair_key, data_points in plot_data[name].items():\n",
    "        rates = data_points['rates']\n",
    "        overlaps = data_points['overlaps']\n",
    "        sorted_pairs = sorted(zip(rates, overlaps), reverse=True)\n",
    "        xs, ys = zip(*sorted_pairs)\n",
    "        \n",
    "        plt.plot(xs, ys, marker='o', linewidth=2, label=pair_key)\n",
    "        \n",
    "    plt.xlabel(\"Retention Rate\")\n",
    "    plt.ylabel(\"Overlap\")\n",
    "    plt.gca().invert_xaxis()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0, 1.05)\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge Selection Diversity\n",
    "\n",
    "The overlap analysis reveals important insights about method similarity:\n",
    "\n",
    "**Scientific Findings:**\n",
    "- **Low overlap between Random and structural methods**: Random sparsification shows minimal agreement with Jaccard, Adamic-Adar, and Effective Resistance, confirming these structural methods capture non-random patterns\n",
    "- **High overlap between similarity-based methods**: Jaccard and Adamic-Adar show high overlap, suggesting they both identify edges that preserve community structure\n",
    "- **Effective Resistance distinctiveness**: Shows moderate overlap with similarity-based methods, as it prioritizes bridge edges and bottlenecks—a complementary criterion to neighborhood similarity\n",
    "- **Retention rate dependency**: Overlap generally decreases at lower retention rates, indicating methods disagree more about which edges are \"least important\"\n",
    "\n",
    "This demonstrates that structural sparsification methods capture meaningful topological patterns, making principled decisions about edge importance rather than arbitrary selection. Each method emphasizes different structural features: Jaccard/Adamic-Adar focus on community cohesion, while Effective Resistance identifies critical connectivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric Backbone Comparison\n",
    "\n",
    "We now analyze how Metric Backbone's edge selection compares to the other methods. Since Metric Backbone operates on a different parameter (alpha), we compare it at similar retention ratios achieved by different alpha values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_comparison_data = {}\n",
    "\n",
    "# Methods to compare against (excluding random)\n",
    "comparison_methods = ['jaccard', 'adamic-adar', 'approx-effective-resistance']\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    print(f\"\\n{'='*30}\\n METRIC BACKBONE COMPARISON: {name.capitalize()}\\n{'='*30}\")\n",
    "    \n",
    "    edge_index_cpu = data.edge_index.cpu()\n",
    "    adj = to_scipy_sparse_matrix(edge_index_cpu, num_nodes=data.num_nodes).tocsr()\n",
    "    jaccard_sim = calculate_jaccard_scores(adj)\n",
    "    jaccard_dist = 1.0 - jaccard_sim\n",
    "    \n",
    "    # Precompute scores for each method once\n",
    "    print(\"Precomputing method scores...\")\n",
    "    method_cache = {}\n",
    "    for method in comparison_methods:\n",
    "        print(f\"  {method}...\", end=\" \", flush=True)\n",
    "        method_cache[method] = compute_method_scores(data, method)\n",
    "        print(\"done\")\n",
    "    \n",
    "    mb_comparison_data[name] = {'alpha': [], 'retention': []}\n",
    "    \n",
    "    for method in comparison_methods:\n",
    "        mb_comparison_data[name][f'overlap_with_{method}'] = []\n",
    "    \n",
    "    for alpha in alpha_values:\n",
    "        sparse_data, stats = metric_backbone_sparsify(data, jaccard_dist, alpha=alpha, verbose=False)\n",
    "        mb_edges = get_edge_set(sparse_data.edge_index)\n",
    "        retention = stats['retention_ratio']\n",
    "        \n",
    "        mb_comparison_data[name]['alpha'].append(alpha)\n",
    "        mb_comparison_data[name]['retention'].append(retention)\n",
    "        \n",
    "        target_rate = retention\n",
    "        \n",
    "        for method in comparison_methods:\n",
    "            scores, edge_index = method_cache[method]\n",
    "            method_edges = get_sparsified_edges_from_scores(scores, edge_index, target_rate)\n",
    "            \n",
    "            if len(mb_edges) == 0 and len(method_edges) == 0:\n",
    "                overlap = 1.0\n",
    "            else:\n",
    "                intersection = len(mb_edges.intersection(method_edges))\n",
    "                union = len(mb_edges.union(method_edges))\n",
    "                overlap = intersection / union if union > 0 else 0.0\n",
    "            \n",
    "            mb_comparison_data[name][f'overlap_with_{method}'].append(overlap)\n",
    "        \n",
    "        print(f\"α={alpha:.1f}: Retention={retention:.2%}, \"\n",
    "              f\"Overlap with Jaccard={mb_comparison_data[name]['overlap_with_jaccard'][-1]:.2%}, \"\n",
    "              f\"Overlap with Adamic-Adar={mb_comparison_data[name]['overlap_with_adamic-adar'][-1]:.2%}, \"\n",
    "              f\"Overlap with Approx-ER={mb_comparison_data[name]['overlap_with_approx-effective-resistance'][-1]:.2%}\")\n",
    "\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, name in enumerate(dataset_names):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    plt.title(f\"{name.capitalize()} - Metric Backbone vs Others\", fontsize=14)\n",
    "    \n",
    "    retentions = mb_comparison_data[name]['retention']\n",
    "    \n",
    "    plt.plot(retentions, mb_comparison_data[name]['overlap_with_jaccard'], \n",
    "             marker='o', linewidth=2, label='vs Jaccard')\n",
    "    plt.plot(retentions, mb_comparison_data[name]['overlap_with_adamic-adar'], \n",
    "             marker='s', linewidth=2, label='vs Adamic-Adar')\n",
    "    plt.plot(retentions, mb_comparison_data[name]['overlap_with_approx-effective-resistance'], \n",
    "             marker='^', linewidth=2, label='vs Approx-ER')\n",
    "    \n",
    "    plt.xlabel(\"Retention Rate\")\n",
    "    plt.ylabel(\"Edge Overlap (Jaccard)\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.ylim(0, 1.05)\n",
    "    if i == 0:\n",
    "        plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric Backbone Selection Analysis\n",
    "\n",
    "The analysis reveals how Metric Backbone's geometric approach differs from other structural methods:\n",
    "\n",
    "**Scientific Findings:**\n",
    "- **Moderate overlap with similarity-based methods**: Metric Backbone shows partial agreement with Jaccard and Adamic-Adar, suggesting it captures some similar structural patterns while also identifying unique redundancies\n",
    "- **Distinctive from Effective Resistance**: While Effective Resistance identifies critical bridge edges, Metric Backbone removes redundant edges where efficient detours exist—complementary but distinct geometric perspectives\n",
    "- **Geometric vs. Similarity-based pruning**: While Jaccard/Adamic-Adar preserve edges with high neighborhood overlap, Metric Backbone removes edges where efficient detours exist through triangles—a fundamentally different criterion\n",
    "- **Retention-dependent behavior**: The overlap varies with retention rate, indicating that at different sparsity levels, the methods prioritize different structural features\n",
    "- **Complementary perspectives**: The distinct edge selections suggest these methods could be combined to capture multiple aspects of graph structure\n",
    "\n",
    "This demonstrates that Metric Backbone provides a principled geometric perspective on edge importance, based on the Relaxed Triangle Inequality, which complements both the neighborhood-similarity perspective of Jaccard/Adamic-Adar and the connectivity-criticality perspective of Effective Resistance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook systematically analyzed how different sparsification methods affect graph topology across multiple benchmark datasets. \n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Structural Preservation**: Structural methods (Jaccard, Adamic-Adar, Effective Resistance) preserve graph structure better than random removal at equivalent retention rates, maintaining connectivity and degree distribution more effectively.\n",
    "\n",
    "2. **Similarity-based Convergence**: Jaccard and Adamic-Adar show high overlap in edge selection, suggesting they capture similar structural patterns—edges connecting nodes with many common neighbors.\n",
    "\n",
    "3. **Effective Resistance Uniqueness**: Effective Resistance identifies critical bridge edges and bottlenecks, providing a complementary perspective focused on connectivity rather than community structure. It shows moderate overlap with similarity-based methods.\n",
    "\n",
    "4. **Geometric Perspective**: Metric Backbone offers a fundamentally different approach based on the Relaxed Triangle Inequality. It identifies and removes redundant edges where efficient alternative paths exist, providing a complementary geometric view of edge importance.\n",
    "\n",
    "5. **Dataset Generalization**: The relative behavior of methods is consistent across datasets of varying sizes and structures (citation networks, social networks), suggesting these findings generalize beyond specific graph types.\n",
    "\n",
    "6. **Retention Rate Dependency**: As graphs become sparser (lower retention rates), methods diverge more in their edge selection, highlighting their different criteria for identifying \"important\" edges.\n",
    "\n",
    "### Methodological Insights:\n",
    "\n",
    "- **Community Cohesion** (Jaccard, Adamic-Adar): Preserve edges within densely connected clusters\n",
    "- **Critical Connectivity** (Effective Resistance): Maintain bottleneck edges essential for graph connectivity\n",
    "- **Geometric Efficiency** (Metric Backbone): Remove edges that violate the relaxed triangle inequality\n",
    "\n",
    "### Implications for GNN Sparsification:\n",
    "\n",
    "These topological analyses provide the foundation for understanding how sparsification will affect GNN performance. Methods that better preserve connectivity and community structure should maintain information flow in message-passing neural networks. The diversity of structural criteria (community cohesion, critical connectivity, geometric efficiency) suggests that different methods may be optimal for different graph types or downstream tasks. The next steps involve evaluating how these topological differences translate to downstream task performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
